{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Workflow for feature testing and comparison\n",
        "\n",
        "We are testing multiple ways to describe the calibration information in order to find suitable features to solve this classification problem.\n",
        "Therefore, we have generated a workflow where feature testing can be done, and the modelling performance with (at least) three different classification algorithm are reported in an excel file (modelling_results.csv). To keep the results comparable, the exact same workflow is used for testing in order to avoid reporting differences due to randomization and different splitting of the training and test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries and read in cleaned data\n",
        "\n",
        "Data cleaning (done by Yvonne) and following steps were taken:\n",
        "- removing rows with nan in RT\n",
        "- removing rows with nan in concentration\n",
        "- removing calibration graphs with only 1 or 2 calibration points\n",
        "\n",
        "Data set contains 3860 rows and no nan values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uKLeYc9YGqOJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3860 entries, 0 to 3859\n",
            "Data columns (total 26 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   lab                  3860 non-null   object \n",
            " 1   compound             3860 non-null   object \n",
            " 2   sample_type          3860 non-null   object \n",
            " 3   RT                   3860 non-null   float64\n",
            " 4   sample               3860 non-null   object \n",
            " 5   peak_area            3860 non-null   float64\n",
            " 6   note                 3860 non-null   object \n",
            " 7   c_real_M             3860 non-null   float64\n",
            " 8   rf                   3860 non-null   float64\n",
            " 9   rf_error             3860 non-null   float64\n",
            " 10  slope                3860 non-null   float64\n",
            " 11  intercept            3860 non-null   float64\n",
            " 12  residuals            3860 non-null   float64\n",
            " 13  abs_residuals        3860 non-null   float64\n",
            " 14  peak_area_norm1      3860 non-null   float64\n",
            " 15  c_real_M_norm1       3860 non-null   float64\n",
            " 16  rf_norm1             3860 non-null   float64\n",
            " 17  rf_error_norm1       3860 non-null   float64\n",
            " 18  residuals_norm1      3860 non-null   float64\n",
            " 19  abs_residuals_norm1  3860 non-null   float64\n",
            " 20  peak_area_norm2      3860 non-null   float64\n",
            " 21  c_real_M_norm2       3860 non-null   float64\n",
            " 22  rf_norm2             3860 non-null   float64\n",
            " 23  rf_error_norm2       3860 non-null   float64\n",
            " 24  residuals_norm2      3860 non-null   float64\n",
            " 25  abs_residuals_norm2  3860 non-null   float64\n",
            "dtypes: float64(21), object(5)\n",
            "memory usage: 784.2+ KB\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import *\n",
        "\n",
        "# data\n",
        "file_path = \"C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/ML_calibration_graph_linearity/0_data/data_ready_addfeatures_231122.csv\"\n",
        "#file_path = \".../ML_calibration_graph_linearity/0_data/data_ready_231029.csv\"\n",
        "df_calibrations = pd.read_csv(file_path)\n",
        "df_calibrations.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature engineering\n",
        "\n",
        "Define features used for modelling here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# new features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plotting, if needed\n",
        "fig = (\n",
        "    ggplot(data = df_calibrations,\n",
        "          mapping = aes(x = 'c_real_M', y = 'peak_area')) +\n",
        "    geom_point(aes(color = \"factor(note)\")) +\n",
        "    scale_color_manual(values=(\"lightgreen\", \"red\")) +\n",
        "    theme_bw() +\n",
        "    #scale_y_log10() +\n",
        "    #scale_x_log10() + \n",
        "\n",
        "    facet_wrap(\"compound\",\n",
        "               ncol=4,\n",
        "               scales=\"free\") +\n",
        "    theme(figure_size = (16, 30),\n",
        "          axis_line = element_line(size = 0.5, colour = \"black\"),\n",
        "          panel_grid_major = element_line(size = 0.05, colour = \"black\"),\n",
        "          panel_grid_minor = element_line(size = 0.05, colour = \"black\"),\n",
        "          axis_text = element_text(colour ='black'),\n",
        "          aspect_ratio=1\n",
        "          ) \n",
        ")\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here we should maybe add the density plots that Yvonne was also showing to show if there is a potential in classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelling\n",
        "\n",
        "Using default values here\n",
        "\n",
        "- Decision Tree\n",
        "- KNN\n",
        "- Random Forest\n",
        "- xgboost?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UG1dvMEoRSbC"
      },
      "outputs": [],
      "source": [
        "# Split dataset into features and target variable\n",
        "X = df_calibrations[['RT','peak_area','c_real_M']]\n",
        "y = df_calibrations[['note']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PvHrHLsyS4Xz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3088, 3)\n",
            "(3088, 1)\n",
            "(772, 3)\n",
            "(772, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "np.random.seed(123)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 80% training and 20% test\n",
        "\n",
        "print(X_train.shape) #(3134, 3)\n",
        "print(y_train.shape) #(3134, 1)\n",
        "print(X_test.shape) #(784, 3)\n",
        "print(y_test.shape) #(784, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores of DT: 66.14493684108616%\n",
            "Accuracy of DT on test set: 66.96428571428571%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "np.random.seed(123) # random seed for consistency\n",
        "DT_model = DecisionTreeClassifier()\n",
        "\n",
        "# cross-validate\n",
        "cv_scores1 = cross_val_score(DT_model, X_train, y_train, cv=5)\n",
        "print(f'Cross-validation scores of DT: {np.mean(cv_scores1)*100}%')\n",
        "\n",
        "# train classifiers\n",
        "DT_model.fit(X_train, y_train)\n",
        "\n",
        "# predict validation set\n",
        "X_test['DT_note_pred'] = DT_model.predict(X_test[['RT','peak_area','c_real_M']])\n",
        "\n",
        "print(f\"Accuracy of DT on test set: {DT_model.score(X_test[['RT','peak_area','c_real_M']], y_test[['note']])*100}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores of KNN: 52.493797632347786%\n",
            "Accuracy of KNN on test set: 51.29533678756477%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "np.random.seed(123) # random seed for consistency\n",
        "KNN_model = KNeighborsClassifier()\n",
        "\n",
        "# cross-validate\n",
        "cv_scores2 = cross_val_score(KNN_model, X_train, y_train['note'], cv=5)\n",
        "print(f'Cross-validation scores of KNN: {np.mean(cv_scores2)*100}%')\n",
        "\n",
        "# train classifiers\n",
        "KNN_model.fit(X_train, y_train['note'])\n",
        "\n",
        "# predict validation set\n",
        "X_test['KNN_note_pred'] = KNN_model.predict(X_test[['RT','peak_area','c_real_M']])\n",
        "\n",
        "print(f\"Accuracy of KNN on test set: {KNN_model.score(X_test[['RT','peak_area','c_real_M']], y_test[['note']])*100}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores of RF: 66.02922587108516%\n",
            "Accuracy of RF on test set: 67.35751295336787%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "np.random.seed(123) # random seed for consistency\n",
        "RF_model = RandomForestClassifier()\n",
        "\n",
        "# cross-validate\n",
        "cv_scores3 = cross_val_score(RF_model, X_train, y_train['note'], cv=5)\n",
        "print(f'Cross-validation scores of RF: {np.mean(cv_scores3)*100}%')\n",
        "\n",
        "# train classifiers\n",
        "RF_model.fit(X_train, y_train['note'])\n",
        "\n",
        "# predict validation set\n",
        "X_test['RF_note_pred'] = RF_model.predict(X_test[['RT','peak_area','c_real_M']])\n",
        "\n",
        "print(f\"Accuracy of RF on test set: {RF_model.score(X_test[['RT','peak_area','c_real_M']], y_test[['note']])*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of XGBoost on the test set: 0.75\n"
          ]
        }
      ],
      "source": [
        "#pip install -q xgboost\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create a XGBoost Classifier\n",
        "xgboost = xgb.XGBClassifier(n_estimators=100)\n",
        "\n",
        "# Train the model using the training sets y_pred=xgboost.predict(X_test)\n",
        "xgboost.fit(X_train,y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = xgboost.predict(X_test)\n",
        "\n",
        "print(\"Accuracy of XGBoost on the test set:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# I am struggling getting this one working, but Gordian was using some other XGBoost that did not need all the preprocessing?\n",
        "\n",
        "'''\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# tranform labels\n",
        "mapping = {'linear': 1, 'non-linear': 0}\n",
        "y_train['note'] = y_train['note'].replace(mapping)\n",
        "y_test['note'] = y_test['note'].replace(mapping)\n",
        "\n",
        "# transform data\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train['note'].values.ravel(), enable_categorical = True)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test['note'].values.ravel(), enable_categorical = True)\n",
        "\n",
        "# Define the XGBoost parameters \n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"num_class\": 2,\n",
        "    \"eval_metric\": [\"error\"]\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "np.random.seed(123) # random seed for consistency\n",
        "XGB_model = xgb.train(params, dtrain, num_boost_round = 25)\n",
        "\n",
        "# predict validation set\n",
        "ypred = XGB_model.predict(dtest)\n",
        "print(f\"The accuracy of XGBoost model is {np.sum(y_test == ypred)/len(y_test)*100}%.\")\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The plotting could be useful here, but can only be done for data with two variables\n",
        "# I did not debug this code yet \n",
        "\n",
        "'''\n",
        "\n",
        "def draw_points_ggplot2(point_set):\n",
        "  fig = (\n",
        "    ggplot(data = point_set,\n",
        "          mapping = aes(x = 'x1', y = 'x2')) +\n",
        "    geom_point(aes(colour = 'class',\n",
        "                   shape = 'class',\n",
        "                   fill = 'class'),\n",
        "               size = 5.0,\n",
        "               stroke = 2.5) +\n",
        "    labs(\n",
        "        title ='',\n",
        "        x = 'x1',\n",
        "        y = 'x2',\n",
        "    ) +\n",
        "    theme_bw() +\n",
        "    scale_color_manual(['#EC5D57', '#51A7F9']) +\n",
        "    scale_fill_manual(['#C82506', '#0365C0']) +\n",
        "    scale_shape_manual(['o', 's']) +\n",
        "    theme(figure_size = (5, 5),\n",
        "          axis_line = element_line(size = 0.5, colour = \"black\"),\n",
        "          panel_grid_major = element_line(size = 0.05, colour = \"black\"),\n",
        "          panel_grid_minor = element_line(size = 0.05, colour = \"black\"),\n",
        "          axis_text = element_text(colour ='black'))\n",
        "  )\n",
        "  return(fig)\n",
        "\n",
        "def generate_grid(start, stop, ppu):\n",
        "  \"\"\"\n",
        "  Function that creates data for the\n",
        "  decision boundary visualisation.\n",
        "  \"\"\"\n",
        "  num_points = (stop - start)*ppu\n",
        "  x = np.linspace(start, stop, num_points)\n",
        "  y = np.linspace(start, stop, num_points)\n",
        "  xx, yy = np.meshgrid(x, y)\n",
        "  x1, x2 = xx.flatten(), yy.flatten()\n",
        "  return(pd.DataFrame({'x1':  x1, 'x2': x2}))\n",
        "\n",
        "start = -3\n",
        "stop = 4\n",
        "ppu = 25 # points per unit\n",
        "\n",
        "grid_data = generate_grid(start, stop, ppu)\n",
        "print(grid_data.shape) # it should be (19600, 2)\n",
        "\n",
        "grid_data['model1'] = DT_model.predict(grid_data[['x1', 'x2']])\n",
        "\n",
        "draw_points_ggplot2(X_test) + geom_point(data = grid_data, mapping = aes(x = 'x1', y = 'x2', colour = 'factor(model1)'),  size = .5, alpha = 0.2) + annotate(\"text\", label = \"DT\", x = 2.5, y = 3.5, size = 12, colour = \"black\")\n",
        "'''\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
