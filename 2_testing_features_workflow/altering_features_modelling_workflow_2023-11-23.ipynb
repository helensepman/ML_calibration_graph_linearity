{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U2_OTs6kNQv"
      },
      "source": [
        "# Workflow for feature testing and comparison\n",
        "\n",
        "We are testing multiple ways to describe the calibration information in order to find suitable features to solve this classification problem.\n",
        "Therefore, we have generated a workflow where feature testing can be done, and the modelling performance with (at least) three different classification algorithm are reported in an excel file (modelling_results.csv). To keep the results comparable, the exact same workflow is used for testing in order to avoid reporting differences due to randomization and different splitting of the training and test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBt9EyDnkNQx"
      },
      "source": [
        "## Libraries and read in cleaned data\n",
        "\n",
        "Data cleaning (done by Yvonne) and following steps were taken:\n",
        "- removing rows with nan in RT\n",
        "- removing rows with nan in concentration\n",
        "- removing calibration graphs with only 1 or 2 calibration points\n",
        "\n",
        "Data set contains 3860 rows and no nan values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uKLeYc9YGqOJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "504663ca-5ac0-40b9-a56f-fe8d21d29d37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c44bd7b7-b3f9-48e1-9381-83a6b0446711\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c44bd7b7-b3f9-48e1-9381-83a6b0446711\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_ready_addfeatures_231122.csv to data_ready_addfeatures_231122.csv\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import *\n",
        "\n",
        "# data\n",
        "#file_path = \"C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/ML_calibration_graph_linearity/0_data/data_ready_addfeatures_231122.csv\"\n",
        "##file_path = \".../ML_calibration_graph_linearity/0_data/data_ready_231029.csv\"\n",
        "#df_calibrations = pd.read_csv(file_path)\n",
        "#df_calibrations.info()\n",
        "\n",
        "## load data to google colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"data_ready_addfeatures_231122.csv\"\n",
        "df_calibrations = pd.read_csv(file_path)\n",
        "df_calibrations.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7o6zGXQpJho",
        "outputId": "fef4362f-0576-4306-85cf-bd0247ebdc50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3860 entries, 0 to 3859\n",
            "Data columns (total 26 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   lab                  3860 non-null   object \n",
            " 1   compound             3860 non-null   object \n",
            " 2   sample_type          3860 non-null   object \n",
            " 3   RT                   3860 non-null   float64\n",
            " 4   sample               3860 non-null   object \n",
            " 5   peak_area            3860 non-null   float64\n",
            " 6   note                 3860 non-null   object \n",
            " 7   c_real_M             3860 non-null   float64\n",
            " 8   rf                   3860 non-null   float64\n",
            " 9   rf_error             3860 non-null   float64\n",
            " 10  slope                3860 non-null   float64\n",
            " 11  intercept            3860 non-null   float64\n",
            " 12  residuals            3860 non-null   float64\n",
            " 13  abs_residuals        3860 non-null   float64\n",
            " 14  peak_area_norm1      3860 non-null   float64\n",
            " 15  c_real_M_norm1       3860 non-null   float64\n",
            " 16  rf_norm1             3860 non-null   float64\n",
            " 17  rf_error_norm1       3860 non-null   float64\n",
            " 18  residuals_norm1      3860 non-null   float64\n",
            " 19  abs_residuals_norm1  3860 non-null   float64\n",
            " 20  peak_area_norm2      3860 non-null   float64\n",
            " 21  c_real_M_norm2       3860 non-null   float64\n",
            " 22  rf_norm2             3860 non-null   float64\n",
            " 23  rf_error_norm2       3860 non-null   float64\n",
            " 24  residuals_norm2      3860 non-null   float64\n",
            " 25  abs_residuals_norm2  3860 non-null   float64\n",
            "dtypes: float64(21), object(5)\n",
            "memory usage: 784.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulKQTEyHkNQ0"
      },
      "source": [
        "## Feature engineering\n",
        "\n",
        "Define features used for modelling here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rphw_oF5kNQ0"
      },
      "outputs": [],
      "source": [
        "# new features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKDaDO9vkNQ0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting, if needed\n",
        "fig = (\n",
        "    ggplot(data = df_calibrations,\n",
        "          mapping = aes(x = 'c_real_M', y = 'peak_area')) +\n",
        "    geom_point(aes(color = \"factor(note)\")) +\n",
        "    scale_color_manual(values=(\"lightgreen\", \"red\")) +\n",
        "    theme_bw() +\n",
        "    #scale_y_log10() +\n",
        "    #scale_x_log10() +\n",
        "\n",
        "    facet_wrap(\"compound\",\n",
        "               ncol=4,\n",
        "               scales=\"free\") +\n",
        "    theme(figure_size = (16, 30),\n",
        "          axis_line = element_line(size = 0.5, colour = \"black\"),\n",
        "          panel_grid_major = element_line(size = 0.05, colour = \"black\"),\n",
        "          panel_grid_minor = element_line(size = 0.05, colour = \"black\"),\n",
        "          axis_text = element_text(colour ='black'),\n",
        "          aspect_ratio=1\n",
        "          )\n",
        ")\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfnDkMCvkNQ1"
      },
      "outputs": [],
      "source": [
        "# Here we should maybe add the density plots that Yvonne was also showing to show if there is a potential in classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW64v1r8kNQ1"
      },
      "source": [
        "## Modelling\n",
        "\n",
        "Using default values here\n",
        "\n",
        "- Decision Tree\n",
        "- KNN\n",
        "- Random Forest\n",
        "- xgboost?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Decide on features for modelling\n",
        "features = ['peak_area','c_real_M']\n",
        "#features = ['RT','peak_area','c_real_M']\n",
        "#features = ['RT','peak_area','c_real_M', 'rf', 'rf_error']\n",
        "#features = ['RT','peak_area','c_real_M', 'rf', 'rf_error', 'slope', 'intercept', 'residuals', 'abs_residuals']\n",
        "#features = ['RT','peak_area_norm1','c_real_M_norm1', 'rf_norm1', 'rf_error_norm1', 'slope', 'intercept', 'residuals_norm1', 'abs_residuals_norm1'] # best features\n",
        "#eatures = ['RT','peak_area_norm2','c_real_M_norm2', 'rf_norm2', 'rf_error_norm2', 'slope', 'intercept', 'residuals_norm2', 'abs_residuals_norm2']"
      ],
      "metadata": {
        "id": "WliS5ii_PVS3"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "UG1dvMEoRSbC"
      },
      "outputs": [],
      "source": [
        "# Split dataset into features and target variable\n",
        "X = df_calibrations[features]\n",
        "y = df_calibrations[['note']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "PvHrHLsyS4Xz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e928f27b-fff0-4d62-f718-6e3da88283b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3088, 2)\n",
            "(3088, 1)\n",
            "(772, 2)\n",
            "(772, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "np.random.seed(123)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 80% training and 20% test\n",
        "\n",
        "print(X_train.shape) #(3134, 3)\n",
        "print(y_train.shape) #(3134, 1)\n",
        "print(X_test.shape) #(784, 3)\n",
        "print(y_test.shape) #(784, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree Classifier"
      ],
      "metadata": {
        "id": "rpZFpiFmUdb-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLQXD44wkNQ2",
        "outputId": "5f0b8f9f-921c-48ed-a937-3877523e2a47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores of DT: 55.01932830849763%\n",
            "Accuracy of DT on test set: 51.16580310880829%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "np.random.seed(123) # random seed for consistency\n",
        "DT_model = DecisionTreeClassifier()\n",
        "\n",
        "# cross-validate\n",
        "cv_scores1 = cross_val_score(DT_model, X_train, y_train, cv=5)\n",
        "print(f'Cross-validation scores of DT: {np.mean(cv_scores1)*100}%')\n",
        "\n",
        "# train classifiers\n",
        "DT_model.fit(X_train, y_train)\n",
        "\n",
        "# predict validation set\n",
        "X_test['DT_note_pred'] = DT_model.predict(X_test[features])\n",
        "\n",
        "print(f\"Accuracy of DT on test set: {DT_model.score(X_test[features], y_test[['note']])*100}%\")  #['RT','peak_area','c_real_M']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "LNXUZRCqUhTo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsoH7qgikNQ2",
        "outputId": "1975497f-c4ee-4cac-ae72-361a6a8e9307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores of KNN: 52.42907271325392%\n",
            "Accuracy of KNN on test set: 51.554404145077726%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "np.random.seed(123) # random seed for consistency\n",
        "KNN_model = KNeighborsClassifier()\n",
        "\n",
        "# cross-validate\n",
        "cv_scores2 = cross_val_score(KNN_model, X_train, y_train['note'], cv=5)\n",
        "print(f'Cross-validation scores of KNN: {np.mean(cv_scores2)*100}%')\n",
        "\n",
        "# train classifiers\n",
        "KNN_model.fit(X_train, y_train['note'])\n",
        "\n",
        "# predict validation set\n",
        "X_test['KNN_note_pred'] = KNN_model.predict(X_test[features])\n",
        "\n",
        "print(f\"Accuracy of KNN on test set: {KNN_model.score(X_test[features], y_test[['note']])*100}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest"
      ],
      "metadata": {
        "id": "E86PBExhUjxI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77p-58A0kNQ3",
        "outputId": "54eed12c-8bda-4de9-ccdb-6ac0129fa2b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores of RF: 58.32229233214269%\n",
            "Accuracy of RF on test set: 60.62176165803109%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "np.random.seed(123) # random seed for consistency\n",
        "RF_model = RandomForestClassifier()\n",
        "\n",
        "# cross-validate\n",
        "cv_scores3 = cross_val_score(RF_model, X_train, y_train['note'], cv=5)\n",
        "print(f'Cross-validation scores of RF: {np.mean(cv_scores3)*100}%')\n",
        "\n",
        "# train classifiers\n",
        "RF_model.fit(X_train, y_train['note'])\n",
        "\n",
        "# predict validation set\n",
        "X_test['RF_note_pred'] = RF_model.predict(X_test[features])\n",
        "\n",
        "print(f\"Accuracy of RF on test set: {RF_model.score(X_test[features], y_test[['note']])*100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extreme gradient boosting"
      ],
      "metadata": {
        "id": "GVfckuqKUob_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXwE1c_3kNQ3",
        "outputId": "a3d8bf86-ee58-4b48-c938-74ccc454872f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores of xgboost: 69.39754422956891%\n",
            "Accuracy of xgboost on test set: 67.09844559585493%\n"
          ]
        }
      ],
      "source": [
        "#pip install -q xgboost\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create a XGBoost Classifier\n",
        "np.random.seed(123)\n",
        "xgboost = xgb.XGBClassifier(n_estimators=100)\n",
        "\n",
        "# cross-validate\n",
        "cv_scores4 = cross_val_score(xgboost, X_train, y_train['note'], cv=5)\n",
        "print(f'Cross-validation scores of xgboost: {np.mean(cv_scores4)*100}%')\n",
        "\n",
        "# Train the model using the training sets y_pred=xgboost.predict(X_test)\n",
        "xgboost.fit(X_train,y_train['note'])\n",
        "\n",
        "X_test['xgboost_note_pred'] = xgboost.predict(X_test[features])\n",
        "\n",
        "print(f\"Accuracy of xgboost on test set: {xgboost.score(X_test[features], y_test[['note']])*100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving the ensemble models"
      ],
      "metadata": {
        "id": "Vmebccp7UN_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I am struggling getting this one working, but Gordian was using some other XGBoost that did not need all the preprocessing?\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# transform data\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train['note'], enable_categorical = True)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test['note'], enable_categorical = True)\n",
        "\n",
        "# Define the XGBoost parameters\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    #\"num_class\": 2,   ## This code works, when taking out num_class, not required for binary class problem, but gives an accuracy of 0%.\n",
        "    \"eval_metric\": [\"error\"]\n",
        "}\n",
        "\n",
        "\n",
        "np.random.seed(123) # random seed for consistency\n",
        "xgboost = xgb.train(params, dtrain, num_boost_round = 25)\n",
        "\n",
        "X_test['xgboost_note_pred'] = xgboost.predict(X_test[features])\n",
        "\n",
        "threshold = 0.5\n",
        "preds_binary = [1 if i > threshold else 0 for i in preds]\n",
        "\n",
        "print(f\"Accuracy of xgboost on test set: {xgboost.score(preds_binary, y_test[['note']])*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "JkGW7qNfVOBa",
        "outputId": "387d946d-66f0-4fb3-a84f-c06c5d05bb2e"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-186-aa9ddfbaeac5>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xgboost_note_pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \"\"\"\n\u001b[1;32m   2267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting data to be a DMatrix object, got: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Expecting data to be a DMatrix object, got: ', <class 'pandas.core.frame.DataFrame'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install bayesian-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeK9eCpJ22IH",
        "outputId": "52d2e779-c5d4-4008-94d0-da009b9d95ff"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)\n",
            "Collecting colorama>=0.4.6 (from bayesian-optimization)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.2.0)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define the function to optimize\n",
        "def bo_tune_xgb(max_depth, gamma, n_estimators ,learning_rate):\n",
        "    params = {'max_depth': int(max_depth),\n",
        "              'gamma': gamma,\n",
        "              'n_estimators': int(n_estimators),\n",
        "              'learning_rate':learning_rate,\n",
        "              'subsample': 0.8,\n",
        "              'eta': 0.1,\n",
        "              'eval_metric': 'rmse'}\n",
        "    cv_result = xgb.cv(params, dtrain, num_boost_round=50, nfold=5)\n",
        "    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = BayesianOptimization(bo_tune_xgb, {'max_depth': (3, 10),\n",
        "                                               'gamma': (0, 1),\n",
        "                                               'learning_rate':(0,1),\n",
        "                                               'n_estimators':(10,120)},\n",
        "                                 random_state=0)\n",
        "\n",
        "# Optimize\n",
        "optimizer.maximize(n_iter=50, init_points=8)\n",
        "\n",
        "# Extract the best parameters\n",
        "params = optimizer.max['params']\n",
        "params['max_depth'] = int(params['max_depth'])\n",
        "# params['learning_rate'] = int(params['learning_rate']) with this 58.8% accuracy\n",
        "params['n_estimators'] = int(params['n_estimators'])\n",
        "params['objective'] = 'binary:logistic'\n",
        "params['eval_metric'] = 'error'\n",
        "\n",
        "# Train the model with the optimal parameters\n",
        "XGB_model = xgb.train(params, dtrain, num_boost_round = 25)\n",
        "\n",
        "# predict validation set\n",
        "ypred_proba = XGB_model.predict(dtest)\n",
        "ypred = [1 if prob > 0.5 else 0 for prob in ypred_proba]\n",
        "\n",
        "#print(f\"The accuracy of XGBoost model is {np.sum(y_test == ypred)/len(y_test)*100}%.\")\n",
        "print(\"Accuracy of XGBoost on the test set:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_yUKDFH2sVT",
        "outputId": "80e6ec9e-3f41-4a69-d927-8b61f100001a"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |   gamma   | learni... | max_depth | n_esti... |\n",
            "-------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:37] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m1        \u001b[0m | \u001b[0m-0.3991  \u001b[0m | \u001b[0m0.5488   \u001b[0m | \u001b[0m0.7152   \u001b[0m | \u001b[0m7.219    \u001b[0m | \u001b[0m69.94    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:39] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[95m2        \u001b[0m | \u001b[95m-0.3985  \u001b[0m | \u001b[95m0.4237   \u001b[0m | \u001b[95m0.6459   \u001b[0m | \u001b[95m6.063    \u001b[0m | \u001b[95m108.1    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:39] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[95m3        \u001b[0m | \u001b[95m-0.3842  \u001b[0m | \u001b[95m0.9637   \u001b[0m | \u001b[95m0.3834   \u001b[0m | \u001b[95m8.542    \u001b[0m | \u001b[95m68.18    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:40] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m4        \u001b[0m | \u001b[0m-0.3962  \u001b[0m | \u001b[0m0.568    \u001b[0m | \u001b[0m0.9256   \u001b[0m | \u001b[0m3.497    \u001b[0m | \u001b[0m19.58    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:40] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m5        \u001b[0m | \u001b[0m-0.4531  \u001b[0m | \u001b[0m0.02022  \u001b[0m | \u001b[0m0.8326   \u001b[0m | \u001b[0m8.447    \u001b[0m | \u001b[0m105.7    \u001b[0m |\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m-0.4006  \u001b[0m | \u001b[0m0.9786   \u001b[0m | \u001b[0m0.7992   \u001b[0m | \u001b[0m6.23     \u001b[0m | \u001b[0m95.86    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:41] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:41] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m7        \u001b[0m | \u001b[0m-0.3906  \u001b[0m | \u001b[0m0.1183   \u001b[0m | \u001b[0m0.6399   \u001b[0m | \u001b[0m4.003    \u001b[0m | \u001b[0m113.9    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:41] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[95m8        \u001b[0m | \u001b[95m-0.3752  \u001b[0m | \u001b[95m0.5218   \u001b[0m | \u001b[95m0.4147   \u001b[0m | \u001b[95m4.852    \u001b[0m | \u001b[95m95.17    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:42] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m9        \u001b[0m | \u001b[0m-0.3924  \u001b[0m | \u001b[0m0.4505   \u001b[0m | \u001b[0m0.6969   \u001b[0m | \u001b[0m6.155    \u001b[0m | \u001b[0m108.3    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:42] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m10       \u001b[0m | \u001b[0m-0.4087  \u001b[0m | \u001b[0m0.05344  \u001b[0m | \u001b[0m0.02484  \u001b[0m | \u001b[0m4.478    \u001b[0m | \u001b[0m94.41    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:43] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m11       \u001b[0m | \u001b[0m-0.3917  \u001b[0m | \u001b[0m0.9848   \u001b[0m | \u001b[0m0.7794   \u001b[0m | \u001b[0m4.589    \u001b[0m | \u001b[0m95.54    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:43] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m12       \u001b[0m | \u001b[0m-0.3938  \u001b[0m | \u001b[0m0.2717   \u001b[0m | \u001b[0m0.02776  \u001b[0m | \u001b[0m5.09     \u001b[0m | \u001b[0m95.61    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:44] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m13       \u001b[0m | \u001b[0m-0.3856  \u001b[0m | \u001b[0m0.8509   \u001b[0m | \u001b[0m0.562    \u001b[0m | \u001b[0m5.431    \u001b[0m | \u001b[0m94.93    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:44] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m14       \u001b[0m | \u001b[0m-0.3889  \u001b[0m | \u001b[0m0.2827   \u001b[0m | \u001b[0m0.7064   \u001b[0m | \u001b[0m5.299    \u001b[0m | \u001b[0m95.2     \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:45] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m15       \u001b[0m | \u001b[0m-0.3765  \u001b[0m | \u001b[0m0.8265   \u001b[0m | \u001b[0m0.4091   \u001b[0m | \u001b[0m8.86     \u001b[0m | \u001b[0m67.25    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:45] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m16       \u001b[0m | \u001b[0m-0.3826  \u001b[0m | \u001b[0m0.1864   \u001b[0m | \u001b[0m0.4184   \u001b[0m | \u001b[0m9.267    \u001b[0m | \u001b[0m67.73    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:46] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m17       \u001b[0m | \u001b[0m-0.4339  \u001b[0m | \u001b[0m0.3903   \u001b[0m | \u001b[0m0.8989   \u001b[0m | \u001b[0m8.358    \u001b[0m | \u001b[0m67.42    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:46] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m18       \u001b[0m | \u001b[0m-0.4014  \u001b[0m | \u001b[0m0.808    \u001b[0m | \u001b[0m0.7704   \u001b[0m | \u001b[0m8.331    \u001b[0m | \u001b[0m77.82    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:46] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:47] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[95m19       \u001b[0m | \u001b[95m-0.3716  \u001b[0m | \u001b[95m0.755    \u001b[0m | \u001b[95m0.09205  \u001b[0m | \u001b[95m9.296    \u001b[0m | \u001b[95m67.74    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:47] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m20       \u001b[0m | \u001b[0m-0.3853  \u001b[0m | \u001b[0m0.6567   \u001b[0m | \u001b[0m0.6601   \u001b[0m | \u001b[0m5.07     \u001b[0m | \u001b[0m46.28    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:48] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m21       \u001b[0m | \u001b[0m-0.4025  \u001b[0m | \u001b[0m0.9369   \u001b[0m | \u001b[0m0.7373   \u001b[0m | \u001b[0m9.356    \u001b[0m | \u001b[0m67.77    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:48] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m22       \u001b[0m | \u001b[0m-0.3816  \u001b[0m | \u001b[0m0.817    \u001b[0m | \u001b[0m0.4317   \u001b[0m | \u001b[0m6.176    \u001b[0m | \u001b[0m99.46    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:48] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m23       \u001b[0m | \u001b[0m-0.394   \u001b[0m | \u001b[0m0.9799   \u001b[0m | \u001b[0m0.6088   \u001b[0m | \u001b[0m9.661    \u001b[0m | \u001b[0m16.72    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:49] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m24       \u001b[0m | \u001b[0m-0.4986  \u001b[0m | \u001b[0m0.6179   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m9.113    \u001b[0m | \u001b[0m67.33    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:54] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m25       \u001b[0m | \u001b[0m-0.3726  \u001b[0m | \u001b[0m0.7146   \u001b[0m | \u001b[0m0.1997   \u001b[0m | \u001b[0m9.178    \u001b[0m | \u001b[0m67.64    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:55] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m26       \u001b[0m | \u001b[0m-0.377   \u001b[0m | \u001b[0m0.8422   \u001b[0m | \u001b[0m0.2967   \u001b[0m | \u001b[0m7.291    \u001b[0m | \u001b[0m110.2    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:55] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m27       \u001b[0m | \u001b[0m-0.3976  \u001b[0m | \u001b[0m0.5137   \u001b[0m | \u001b[0m0.6619   \u001b[0m | \u001b[0m8.524    \u001b[0m | \u001b[0m17.28    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:55] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:56] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m28       \u001b[0m | \u001b[0m-0.3974  \u001b[0m | \u001b[0m0.7305   \u001b[0m | \u001b[0m0.5936   \u001b[0m | \u001b[0m9.028    \u001b[0m | \u001b[0m67.18    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:56] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[95m29       \u001b[0m | \u001b[95m-0.3689  \u001b[0m | \u001b[95m0.4848   \u001b[0m | \u001b[95m0.2834   \u001b[0m | \u001b[95m4.2      \u001b[0m | \u001b[95m98.2     \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:56] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[95m30       \u001b[0m | \u001b[95m-0.3653  \u001b[0m | \u001b[95m0.24     \u001b[0m | \u001b[95m0.1738   \u001b[0m | \u001b[95m4.298    \u001b[0m | \u001b[95m65.12    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:57] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m31       \u001b[0m | \u001b[0m-0.3829  \u001b[0m | \u001b[0m0.4587   \u001b[0m | \u001b[0m0.6035   \u001b[0m | \u001b[0m4.606    \u001b[0m | \u001b[0m31.24    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:57] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m32       \u001b[0m | \u001b[0m-0.3903  \u001b[0m | \u001b[0m0.4977   \u001b[0m | \u001b[0m0.5151   \u001b[0m | \u001b[0m9.231    \u001b[0m | \u001b[0m67.83    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m33       \u001b[0m | \u001b[0m-0.3724  \u001b[0m | \u001b[0m0.6105   \u001b[0m | \u001b[0m0.3498   \u001b[0m | \u001b[0m4.845    \u001b[0m | \u001b[0m95.03    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m34       \u001b[0m | \u001b[0m-0.3748  \u001b[0m | \u001b[0m0.4414   \u001b[0m | \u001b[0m0.5638   \u001b[0m | \u001b[0m4.269    \u001b[0m | \u001b[0m98.11    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m35       \u001b[0m | \u001b[0m-0.3746  \u001b[0m | \u001b[0m0.717    \u001b[0m | \u001b[0m0.2449   \u001b[0m | \u001b[0m4.225    \u001b[0m | \u001b[0m98.13    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m36       \u001b[0m | \u001b[0m-0.3929  \u001b[0m | \u001b[0m0.9325   \u001b[0m | \u001b[0m0.7288   \u001b[0m | \u001b[0m4.505    \u001b[0m | \u001b[0m95.58    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:29:59] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m37       \u001b[0m | \u001b[0m-0.3655  \u001b[0m | \u001b[0m0.3009   \u001b[0m | \u001b[0m0.1748   \u001b[0m | \u001b[0m4.133    \u001b[0m | \u001b[0m65.22    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m38       \u001b[0m | \u001b[0m-0.3839  \u001b[0m | \u001b[0m0.4906   \u001b[0m | \u001b[0m0.05359  \u001b[0m | \u001b[0m4.096    \u001b[0m | \u001b[0m97.96    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m39       \u001b[0m | \u001b[0m-0.3696  \u001b[0m | \u001b[0m0.2795   \u001b[0m | \u001b[0m0.3841   \u001b[0m | \u001b[0m4.291    \u001b[0m | \u001b[0m65.28    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m40       \u001b[0m | \u001b[0m-0.4014  \u001b[0m | \u001b[0m0.4687   \u001b[0m | \u001b[0m0.7693   \u001b[0m | \u001b[0m6.786    \u001b[0m | \u001b[0m44.45    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:01] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m41       \u001b[0m | \u001b[0m-0.3759  \u001b[0m | \u001b[0m0.6386   \u001b[0m | \u001b[0m0.1022   \u001b[0m | \u001b[0m4.503    \u001b[0m | \u001b[0m65.3     \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:02] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m42       \u001b[0m | \u001b[0m-0.3724  \u001b[0m | \u001b[0m0.764    \u001b[0m | \u001b[0m0.2206   \u001b[0m | \u001b[0m7.84     \u001b[0m | \u001b[0m67.11    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:02] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m43       \u001b[0m | \u001b[0m-0.3797  \u001b[0m | \u001b[0m0.2811   \u001b[0m | \u001b[0m0.6531   \u001b[0m | \u001b[0m3.6      \u001b[0m | \u001b[0m110.6    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:06] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m44       \u001b[0m | \u001b[0m-0.3719  \u001b[0m | \u001b[0m0.7313   \u001b[0m | \u001b[0m0.06019  \u001b[0m | \u001b[0m9.381    \u001b[0m | \u001b[0m67.73    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:07] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m45       \u001b[0m | \u001b[0m-0.3783  \u001b[0m | \u001b[0m0.8702   \u001b[0m | \u001b[0m0.2958   \u001b[0m | \u001b[0m9.036    \u001b[0m | \u001b[0m67.81    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:07] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m46       \u001b[0m | \u001b[0m-0.4081  \u001b[0m | \u001b[0m0.8352   \u001b[0m | \u001b[0m0.9378   \u001b[0m | \u001b[0m7.392    \u001b[0m | \u001b[0m107.2    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:08] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m47       \u001b[0m | \u001b[0m-0.3703  \u001b[0m | \u001b[0m0.517    \u001b[0m | \u001b[0m0.2718   \u001b[0m | \u001b[0m4.254    \u001b[0m | \u001b[0m65.08    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:08] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m48       \u001b[0m | \u001b[0m-0.3824  \u001b[0m | \u001b[0m0.4454   \u001b[0m | \u001b[0m0.6346   \u001b[0m | \u001b[0m3.045    \u001b[0m | \u001b[0m114.8    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:09] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m49       \u001b[0m | \u001b[0m-0.4108  \u001b[0m | \u001b[0m0.1277   \u001b[0m | \u001b[0m0.7163   \u001b[0m | \u001b[0m6.19     \u001b[0m | \u001b[0m100.1    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:09] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m50       \u001b[0m | \u001b[0m-0.3787  \u001b[0m | \u001b[0m0.5584   \u001b[0m | \u001b[0m0.4063   \u001b[0m | \u001b[0m7.699    \u001b[0m | \u001b[0m46.48    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:10] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m51       \u001b[0m | \u001b[0m-0.4144  \u001b[0m | \u001b[0m0.9738   \u001b[0m | \u001b[0m0.9657   \u001b[0m | \u001b[0m5.678    \u001b[0m | \u001b[0m68.6     \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:10] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m52       \u001b[0m | \u001b[0m-0.3792  \u001b[0m | \u001b[0m0.3989   \u001b[0m | \u001b[0m0.5525   \u001b[0m | \u001b[0m4.373    \u001b[0m | \u001b[0m64.98    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:11] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[95m53       \u001b[0m | \u001b[95m-0.365   \u001b[0m | \u001b[95m0.06548  \u001b[0m | \u001b[95m0.4169   \u001b[0m | \u001b[95m4.328    \u001b[0m | \u001b[95m65.02    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:11] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[95m54       \u001b[0m | \u001b[95m-0.3645  \u001b[0m | \u001b[95m0.006902 \u001b[0m | \u001b[95m0.4118   \u001b[0m | \u001b[95m4.417    \u001b[0m | \u001b[95m65.31    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:12] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m55       \u001b[0m | \u001b[0m-0.3738  \u001b[0m | \u001b[0m0.06418  \u001b[0m | \u001b[0m0.1779   \u001b[0m | \u001b[0m3.993    \u001b[0m | \u001b[0m65.17    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:12] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m56       \u001b[0m | \u001b[0m-0.3907  \u001b[0m | \u001b[0m0.9442   \u001b[0m | \u001b[0m0.6142   \u001b[0m | \u001b[0m6.714    \u001b[0m | \u001b[0m60.68    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:13] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m57       \u001b[0m | \u001b[0m-0.4401  \u001b[0m | \u001b[0m0.3695   \u001b[0m | \u001b[0m0.9418   \u001b[0m | \u001b[0m8.746    \u001b[0m | \u001b[0m117.4    \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:13] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m58       \u001b[0m | \u001b[0m-0.4133  \u001b[0m | \u001b[0m0.4838   \u001b[0m | \u001b[0m0.8055   \u001b[0m | \u001b[0m8.013    \u001b[0m | \u001b[0m52.49    \u001b[0m |\n",
            "=========================================================================\n",
            "Accuracy of XGBoost on the test set: 0.8341968911917098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:30:13] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "zO-R_MnpkNQ3",
        "outputId": "bf5490cb-9f9c-485b-ee46-a4827b61bd32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nimport xgboost as xgb\\nfrom sklearn.metrics import accuracy_score\\n\\n# tranform labels\\nmapping = {\\'linear\\': 1, \\'non-linear\\': 0}\\ny_train[\\'note\\'] = y_train[\\'note\\'].replace(mapping)\\ny_test[\\'note\\'] = y_test[\\'note\\'].replace(mapping)\\n\\n# transform data\\ndtrain = xgb.DMatrix(X_train, label=y_train[\\'note\\'].values.ravel(), enable_categorical = True)\\ndtest = xgb.DMatrix(X_test, label=y_test[\\'note\\'].values.ravel(), enable_categorical = True)\\n\\n# Define the XGBoost parameters \\nparams = {\\n    \"objective\": \"binary:logistic\",\\n    \"num_class\": 2,\\n    \"eval_metric\": [\"error\"]\\n}\\n\\n# Train the XGBoost model\\nnp.random.seed(123) # random seed for consistency\\nXGB_model = xgb.train(params, dtrain, num_boost_round = 25)\\n\\n# predict validation set\\nypred = XGB_model.predict(dtest)\\nprint(f\"The accuracy of XGBoost model is {np.sum(y_test == ypred)/len(y_test)*100}%.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# I am struggling getting this one working, but Gordian was using some other XGBoost that did not need all the preprocessing?\n",
        "\n",
        "'''\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# tranform labels\n",
        "mapping = {'linear': 1, 'non-linear': 0}\n",
        "y_train['note'] = y_train['note'].replace(mapping)\n",
        "y_test['note'] = y_test['note'].replace(mapping)\n",
        "\n",
        "# transform data\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train['note'].values.ravel(), enable_categorical = True)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test['note'].values.ravel(), enable_categorical = True)\n",
        "\n",
        "# Define the XGBoost parameters\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"num_class\": 2,\n",
        "    \"eval_metric\": [\"error\"]\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "np.random.seed(123) # random seed for consistency\n",
        "XGB_model = xgb.train(params, dtrain, num_boost_round = 25)\n",
        "\n",
        "# predict validation set\n",
        "ypred = XGB_model.predict(dtest)\n",
        "print(f\"The accuracy of XGBoost model is {np.sum(y_test == ypred)/len(y_test)*100}%.\")\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqI6Rvt0kNQ4"
      },
      "outputs": [],
      "source": [
        "# The plotting could be useful here, but can only be done for data with two variables\n",
        "# I did not debug this code yet\n",
        "\n",
        "'''\n",
        "\n",
        "def draw_points_ggplot2(point_set):\n",
        "  fig = (\n",
        "    ggplot(data = point_set,\n",
        "          mapping = aes(x = 'x1', y = 'x2')) +\n",
        "    geom_point(aes(colour = 'class',\n",
        "                   shape = 'class',\n",
        "                   fill = 'class'),\n",
        "               size = 5.0,\n",
        "               stroke = 2.5) +\n",
        "    labs(\n",
        "        title ='',\n",
        "        x = 'x1',\n",
        "        y = 'x2',\n",
        "    ) +\n",
        "    theme_bw() +\n",
        "    scale_color_manual(['#EC5D57', '#51A7F9']) +\n",
        "    scale_fill_manual(['#C82506', '#0365C0']) +\n",
        "    scale_shape_manual(['o', 's']) +\n",
        "    theme(figure_size = (5, 5),\n",
        "          axis_line = element_line(size = 0.5, colour = \"black\"),\n",
        "          panel_grid_major = element_line(size = 0.05, colour = \"black\"),\n",
        "          panel_grid_minor = element_line(size = 0.05, colour = \"black\"),\n",
        "          axis_text = element_text(colour ='black'))\n",
        "  )\n",
        "  return(fig)\n",
        "\n",
        "def generate_grid(start, stop, ppu):\n",
        "  \"\"\"\n",
        "  Function that creates data for the\n",
        "  decision boundary visualisation.\n",
        "  \"\"\"\n",
        "  num_points = (stop - start)*ppu\n",
        "  x = np.linspace(start, stop, num_points)\n",
        "  y = np.linspace(start, stop, num_points)\n",
        "  xx, yy = np.meshgrid(x, y)\n",
        "  x1, x2 = xx.flatten(), yy.flatten()\n",
        "  return(pd.DataFrame({'x1':  x1, 'x2': x2}))\n",
        "\n",
        "start = -3\n",
        "stop = 4\n",
        "ppu = 25 # points per unit\n",
        "\n",
        "grid_data = generate_grid(start, stop, ppu)\n",
        "print(grid_data.shape) # it should be (19600, 2)\n",
        "\n",
        "grid_data['model1'] = DT_model.predict(grid_data[['x1', 'x2']])\n",
        "\n",
        "draw_points_ggplot2(X_test) + geom_point(data = grid_data, mapping = aes(x = 'x1', y = 'x2', colour = 'factor(model1)'),  size = .5, alpha = 0.2) + annotate(\"text\", label = \"DT\", x = 2.5, y = 3.5, size = 12, colour = \"black\")\n",
        "'''\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}