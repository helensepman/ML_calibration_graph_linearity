{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U2_OTs6kNQv"
      },
      "source": [
        "# Workflow for feature testing and comparison\n",
        "\n",
        "We are testing multiple ways to describe the calibration information in order to find suitable features to solve this classification problem.\n",
        "Therefore, we have generated a workflow where feature testing can be done, and the modelling performance with (at least) three different classification algorithm are reported in an excel file (modelling_results.csv). To keep the results comparable, the exact same workflow is used for testing in order to avoid reporting differences due to randomization and different splitting of the training and test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBt9EyDnkNQx"
      },
      "source": [
        "## Libraries and read in cleaned data\n",
        "\n",
        "Data cleaning (done by Yvonne) and following steps were taken:\n",
        "- removing rows with nan in RT\n",
        "- removing rows with nan in concentration\n",
        "- removing calibration graphs with only 1 or 2 calibration points\n",
        "\n",
        "Data set contains 3860 rows and no nan values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "uKLeYc9YGqOJ",
        "outputId": "504663ca-5ac0-40b9-a56f-fe8d21d29d37"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import *\n",
        "\n",
        "# data\n",
        "file_path = \"C:/Users/loma5202/OneDrive - Kruvelab/PhD/courses/machine_learning/project/ML_calibration_graph_linearity/0_data/data_ready_addfeatures_231122.csv\"\n",
        "df_calibrations = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7o6zGXQpJho",
        "outputId": "fef4362f-0576-4306-85cf-bd0247ebdc50"
      },
      "outputs": [],
      "source": [
        "#file_path = \"data_ready_addfeatures_231122.csv\"\n",
        "#df_calibrations = pd.read_csv(file_path)\n",
        "#df_calibrations.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulKQTEyHkNQ0"
      },
      "source": [
        "## Feature engineering\n",
        "\n",
        "Define features used for modelling here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rphw_oF5kNQ0"
      },
      "outputs": [],
      "source": [
        "# new features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKDaDO9vkNQ0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting, if needed\n",
        "fig = (\n",
        "    ggplot(data = df_calibrations,\n",
        "          mapping = aes(x = 'c_real_M', y = 'peak_area')) +\n",
        "    geom_point(aes(color = \"factor(note)\")) +\n",
        "    scale_color_manual(values=(\"lightgreen\", \"red\")) +\n",
        "    theme_bw() +\n",
        "    #scale_y_log10() +\n",
        "    #scale_x_log10() +\n",
        "\n",
        "    facet_wrap(\"compound\",\n",
        "               ncol=4,\n",
        "               scales=\"free\") +\n",
        "    theme(figure_size = (16, 30),\n",
        "          axis_line = element_line(size = 0.5, colour = \"black\"),\n",
        "          panel_grid_major = element_line(size = 0.05, colour = \"black\"),\n",
        "          panel_grid_minor = element_line(size = 0.05, colour = \"black\"),\n",
        "          axis_text = element_text(colour ='black'),\n",
        "          aspect_ratio=1\n",
        "          )\n",
        ")\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfnDkMCvkNQ1"
      },
      "outputs": [],
      "source": [
        "# Here we should maybe add the density plots that Yvonne was also showing to show if there is a potential in classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW64v1r8kNQ1"
      },
      "source": [
        "## Modelling\n",
        "\n",
        "Try to improve Gordians best performing models with hyperparameter tuning\n",
        "- Random Forest\n",
        "- XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WliS5ii_PVS3"
      },
      "outputs": [],
      "source": [
        "## Decide on features for modelling\n",
        "#features = ['peak_area','c_real_M']\n",
        "#features = ['RT','peak_area','c_real_M']\n",
        "#features = ['RT','peak_area','c_real_M', 'rf', 'rf_error']\n",
        "#features = ['RT','peak_area','c_real_M', 'rf', 'rf_error', 'slope', 'intercept', 'residuals', 'abs_residuals']\n",
        "#features = ['RT','peak_area_norm1','c_real_M_norm1', 'rf_norm1', 'rf_error_norm1', 'slope', 'intercept', 'residuals_norm1', 'abs_residuals_norm1'] # best features\n",
        "#eatures = ['RT','peak_area_norm2','c_real_M_norm2', 'rf_norm2', 'rf_error_norm2', 'slope', 'intercept', 'residuals_norm2', 'abs_residuals_norm2']\n",
        "features = ['RT','peak_area_norm1','c_real_M_norm1', 'rf_norm1', 'slope', 'intercept', 'residuals_norm1', 'abs_residuals_norm1'] # without rf_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UG1dvMEoRSbC"
      },
      "outputs": [],
      "source": [
        "# Split dataset into features and target variable\n",
        "X = df_calibrations[features]\n",
        "y = df_calibrations[['note']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvHrHLsyS4Xz",
        "outputId": "e928f27b-fff0-4d62-f718-6e3da88283b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3088, 8)\n",
            "(3088, 1)\n",
            "(772, 8)\n",
            "(772, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "np.random.seed(123)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 80% training and 20% test\n",
        "\n",
        "print(X_train.shape) #(3134, 3)\n",
        "print(y_train.shape) #(3134, 1)\n",
        "print(X_test.shape) #(784, 3)\n",
        "print(y_test.shape) #(784, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E86PBExhUjxI"
      },
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters for RF: {'criterion': 'entropy', 'max_depth': 20, 'max_samples': 1.0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100}\n",
            "5-fold CV Accuracy: 83.55%\n",
            "Test Set Accuracy: 80.57%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Convert the labels (y_train and y_test) to 2D numpy arrays and flatten into 1D arrays\n",
        "y_train_rf = y_train.values.ravel()\n",
        "y_test_rf = y_test.values.ravel()\n",
        "\n",
        "# Hyperparameter tuning setup\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 4, 7, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'min_weight_fraction_leaf': [0.0, 0.25, 0.5],\n",
        "    'max_samples': [0.1, 0.4, 0.7, 1.0]\n",
        "}\n",
        "\n",
        "# GridSearchCV setup and fitting\n",
        "np.random.seed(123) # random seed for consistency\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state = 1)\n",
        "\n",
        "cv_rf = GridSearchCV(rf_model, param_grid_rf, cv = 5, scoring = \"accuracy\", n_jobs = 8)\n",
        "cv_rf.fit(X_train, y_train_rf)\n",
        "best_parameters_rf = cv_rf.best_params_\n",
        "\n",
        "# Training the best RandomForest model found with GridSearchCV\n",
        "best_rf = RandomForestClassifier(**best_parameters_rf, random_state = 1)\n",
        "best_rf.fit(X_train, y_train_rf)\n",
        "\n",
        "# Cross-validate the best model on the training set\n",
        "cv_scores = cross_val_score(best_rf, X_train, y_train_rf, cv=5, scoring='accuracy')\n",
        "cv_accuracy = (np.mean(cv_scores) * 100)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test_rf = best_rf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "test_accuracy_rf = (accuracy_score(y_test_rf, y_pred_test_rf) * 100)\n",
        "\n",
        "# Print out the hyperparameter settings and results\n",
        "print(f\"Best hyperparameters for RF: {best_parameters_rf}\")\n",
        "print(f'5-fold CV Accuracy: {cv_accuracy:.2f}%')\n",
        "print(f'Test Set Accuracy: {test_accuracy_rf:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVfckuqKUob_"
      },
      "source": [
        "## Extreme gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXwE1c_3kNQ3",
        "outputId": "a3d8bf86-ee58-4b48-c938-74ccc454872f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
