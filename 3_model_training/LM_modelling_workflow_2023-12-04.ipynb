{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U2_OTs6kNQv"
      },
      "source": [
        "# Workflow for models training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBt9EyDnkNQx"
      },
      "source": [
        "## Libraries and read in cleaned data\n",
        "\n",
        "Data cleaning (done by Yvonne) and following steps were taken:\n",
        "- removing rows with nan in RT\n",
        "- removing rows with nan in concentration\n",
        "- removing calibration graphs with only 1 or 2 calibration points\n",
        "\n",
        "Data set contains 3860 rows and no nan values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "uKLeYc9YGqOJ",
        "outputId": "504663ca-5ac0-40b9-a56f-fe8d21d29d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3860 entries, 0 to 3859\n",
            "Data columns (total 14 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   lab            3860 non-null   object \n",
            " 1   compound       3860 non-null   object \n",
            " 2   sample_type    3860 non-null   object \n",
            " 3   RT             3860 non-null   float64\n",
            " 4   sample         3860 non-null   object \n",
            " 5   peak_area      3860 non-null   float64\n",
            " 6   note           3860 non-null   object \n",
            " 7   c_real_M       3860 non-null   float64\n",
            " 8   rf             3860 non-null   float64\n",
            " 9   rf_error       3860 non-null   float64\n",
            " 10  slope          3860 non-null   float64\n",
            " 11  intercept      3860 non-null   float64\n",
            " 12  residuals      3860 non-null   float64\n",
            " 13  abs_residuals  3860 non-null   float64\n",
            "dtypes: float64(9), object(5)\n",
            "memory usage: 422.3+ KB\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import *\n",
        "\n",
        "# data\n",
        "# file_path = \"C:/Users/loma5202/OneDrive - Kruvelab/PhD/courses/machine_learning/project/ML_calibration_graph_linearity/0_data/data_ready_addfeatures_231122.csv\"\n",
        "file_path = \"C:/Users/yvkr1259/Documents/data_ready_addfeatures_231122.csv\"\n",
        "\n",
        "df_calibrations = pd.read_csv(file_path)\n",
        "# remove all the normaized columns \n",
        "drop_columns = ['abs_residuals_norm1', 'abs_residuals_norm2','c_real_M_norm1','c_real_M_norm2','peak_area_norm1',\n",
        "'peak_area_norm2','residuals_norm1','residuals_norm2','rf_error_norm1','rf_error_norm2','rf_norm1','rf_norm2']\n",
        "\n",
        "df_calibrations = df_calibrations.drop(drop_columns, axis=1)\n",
        "df_calibrations.info()\n",
        "\n",
        "## load data to google colab\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7o6zGXQpJho",
        "outputId": "fef4362f-0576-4306-85cf-bd0247ebdc50"
      },
      "outputs": [],
      "source": [
        "#file_path = \"data_ready_addfeatures_231122.csv\"\n",
        "#df_calibrations = pd.read_csv(file_path)\n",
        "#df_calibrations.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select features and data splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data splitting should consider that points for each compound per lab belong together. Therefore an individual id for each compound lab pair is introduced. Splitting is then performed based on the id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_calibrations['id'] = df_calibrations['lab'] + '_' + df_calibrations['compound']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvHrHLsyS4Xz",
        "outputId": "e928f27b-fff0-4d62-f718-6e3da88283b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3093, 14)\n",
            "(3093, 1)\n",
            "(767, 14)\n",
            "(767, 1)\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set based on id \n",
        "unique_ids = df_calibrations['id'].unique()\n",
        "np.random.seed(123)\n",
        "train_ids, test_ids = train_test_split(unique_ids, test_size=0.2, random_state=42) # 80% training and 20% test\n",
        "\n",
        "\n",
        "df_train = df_calibrations[df_calibrations['id'].isin(train_ids)]\n",
        "df_test = df_calibrations[df_calibrations['id'].isin(test_ids)]\n",
        "\n",
        "# Split dataset into features and target variable\n",
        "X_train =  df_train.drop('note', axis=1)\n",
        "y_train = df_train[['note']]\n",
        "X_test = df_test.drop('note', axis=1)\n",
        "y_test = df_test[['note']]\n",
        "\n",
        "\n",
        "print(X_train.shape) \n",
        "print(y_train.shape) \n",
        "print(X_test.shape) \n",
        "print(y_test.shape) \n",
        "\n",
        "# (3093, 14)\n",
        "# (3093, 1)\n",
        "# (767, 14)\n",
        "# (767, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In general we decided to try out two different normalisation strategies:\n",
        "\n",
        "**norm1**\n",
        "$$\n",
        "\\text{norm1} = \\frac{\\text{x}}{\\max(\\text{x})}\n",
        "$$\n",
        "\n",
        "**norm2**\n",
        "$$\n",
        "\\text{norm2} = \\frac{\\text{x} - \\min(\\text{x})}{\\max(\\text{x}) - \\min(\\text{x})}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### normalization strategy 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train set \n",
        "X_train['peak_area_norm1'] = X_train.groupby(['lab', 'compound'])['peak_area'].transform(lambda x: x / x.max())\n",
        "X_train['c_real_M_norm1'] = X_train.groupby(['lab', 'compound'])['c_real_M'].transform(lambda x: x / x.max())\n",
        "X_train['rf_norm1'] = X_train.groupby(['lab', 'compound'])['rf'].transform(lambda x: x / x.max())\n",
        "X_train['rf_error_norm1'] = X_train.groupby(['lab', 'compound'])['rf_error'].transform(lambda x: x / x.max())\n",
        "X_train['residuals_norm1'] = X_train.groupby(['lab', 'compound'])['residuals'].transform(lambda x: x / x.max())\n",
        "X_train['abs_residuals_norm1'] = X_train.groupby(['lab', 'compound'])['abs_residuals'].transform(lambda x: x / x.max())\n",
        "\n",
        "# test set \n",
        "X_test['peak_area_norm1'] = X_test.groupby(['lab', 'compound'])['peak_area'].transform(lambda x: x / x.max())\n",
        "X_test['c_real_M_norm1'] = X_test.groupby(['lab', 'compound'])['c_real_M'].transform(lambda x: x / x.max())\n",
        "X_test['rf_norm1'] = X_test.groupby(['lab', 'compound'])['rf'].transform(lambda x: x / x.max())\n",
        "X_test['rf_error_norm1'] = X_test.groupby(['lab', 'compound'])['rf_error'].transform(lambda x: x / x.max())\n",
        "X_test['residuals_norm1'] = X_test.groupby(['lab', 'compound'])['residuals'].transform(lambda x: x / x.max())\n",
        "X_test['abs_residuals_norm1'] = X_test.groupby(['lab', 'compound'])['abs_residuals'].transform(lambda x: x / x.max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### normalization strategy 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "columns_to_scale = ['peak_area', 'c_real_M', 'rf', 'rf_error', 'residuals', 'abs_residuals']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "def scale_columns(group):\n",
        "    for col in columns_to_scale:\n",
        "        group[f'{col}_norm2'] = scaler.fit_transform(group[[col]])\n",
        "    return group\n",
        "\n",
        "\n",
        "X_train = X_train.groupby(['lab', 'compound']).apply(scale_columns)\n",
        "X_test = X_test.groupby(['lab', 'compound']).apply(scale_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WliS5ii_PVS3"
      },
      "outputs": [],
      "source": [
        "## Decide on features for modelling\n",
        "#features = ['peak_area','c_real_M']\n",
        "#features = ['RT','peak_area','c_real_M']\n",
        "#features = ['RT','peak_area','c_real_M', 'rf', 'rf_error']\n",
        "#features = ['RT','peak_area','c_real_M', 'rf', 'rf_error', 'slope', 'intercept', 'residuals', 'abs_residuals']\n",
        "features = ['RT','peak_area_norm1','c_real_M_norm1', 'rf_norm1', 'rf_error_norm1', 'slope', 'intercept', 'residuals_norm1', 'abs_residuals_norm1'] # best features\n",
        "#eatures = ['RT','peak_area_norm2','c_real_M_norm2', 'rf_norm2', 'rf_error_norm2', 'slope', 'intercept', 'residuals_norm2', 'abs_residuals_norm2']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
