{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U2_OTs6kNQv"
      },
      "source": [
        "# Workflow for models training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBt9EyDnkNQx"
      },
      "source": [
        "## Libraries and read in cleaned data\n",
        "\n",
        "Data cleaning (done by Yvonne) and following steps were taken:\n",
        "- removing rows with nan in RT\n",
        "- removing rows with nan in concentration\n",
        "- removing calibration graphs with only 1 or 2 calibration points\n",
        "\n",
        "Data set contains 3860 rows and no nan values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "uKLeYc9YGqOJ",
        "outputId": "504663ca-5ac0-40b9-a56f-fe8d21d29d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3850 entries, 0 to 3849\n",
            "Data columns (total 14 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   lab            3850 non-null   object \n",
            " 1   compound       3850 non-null   object \n",
            " 2   sample_type    3850 non-null   object \n",
            " 3   RT             3850 non-null   float64\n",
            " 4   sample         3850 non-null   object \n",
            " 5   peak_area      3850 non-null   float64\n",
            " 6   note           3850 non-null   object \n",
            " 7   c_real_M       3850 non-null   float64\n",
            " 8   rf             3850 non-null   float64\n",
            " 9   rf_error       3850 non-null   float64\n",
            " 10  slope          3850 non-null   float64\n",
            " 11  intercept      3850 non-null   float64\n",
            " 12  residuals      3850 non-null   float64\n",
            " 13  abs_residuals  3850 non-null   float64\n",
            "dtypes: float64(9), object(5)\n",
            "memory usage: 421.2+ KB\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from plotnine import *\n",
        "\n",
        "# data\n",
        "file_path = \"../0_data/data_ready_addfeatures_231128.csv\"\n",
        "# file_path = \"C:/Users/yvkr1259/Documents/data_ready_addfeatures_231122.csv\"\n",
        "\n",
        "df_calibrations = pd.read_csv(file_path)\n",
        "# remove all the normaized columns \n",
        "drop_columns = ['abs_residuals_norm1', 'abs_residuals_norm2','c_real_M_norm1','c_real_M_norm2','peak_area_norm1',\n",
        "'peak_area_norm2','residuals_norm1','residuals_norm2','rf_error_norm1','rf_error_norm2','rf_norm1','rf_norm2']\n",
        "\n",
        "df_calibrations = df_calibrations.drop(drop_columns, axis=1)\n",
        "df_calibrations.info()\n",
        "\n",
        "## load data to google colab\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7o6zGXQpJho",
        "outputId": "fef4362f-0576-4306-85cf-bd0247ebdc50"
      },
      "outputs": [],
      "source": [
        "#file_path = \"data_ready_addfeatures_231122.csv\"\n",
        "#df_calibrations = pd.read_csv(file_path)\n",
        "#df_calibrations.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select features and data splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data splitting should consider that points for each compound per lab belong together. Therefore an individual id for each compound lab pair is introduced. Splitting is then performed based on the id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_calibrations['id'] = df_calibrations['lab'] + '_' + df_calibrations['compound']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvHrHLsyS4Xz",
        "outputId": "e928f27b-fff0-4d62-f718-6e3da88283b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3084, 14)\n",
            "(3084, 1)\n",
            "(766, 14)\n",
            "(766, 1)\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set based on id \n",
        "unique_ids = df_calibrations['id'].unique()\n",
        "np.random.seed(123)\n",
        "train_ids, test_ids = train_test_split(unique_ids, test_size=0.2, random_state=42) # 80% training and 20% test\n",
        "\n",
        "\n",
        "df_train = df_calibrations[df_calibrations['id'].isin(train_ids)]\n",
        "df_test = df_calibrations[df_calibrations['id'].isin(test_ids)]\n",
        "\n",
        "# Split dataset into features and target variable\n",
        "X_train =  df_train.drop('note', axis=1)\n",
        "y_train = df_train[['note']]\n",
        "X_test = df_test.drop('note', axis=1)\n",
        "y_test = df_test[['note']]\n",
        "\n",
        "\n",
        "print(X_train.shape) \n",
        "print(y_train.shape) \n",
        "print(X_test.shape) \n",
        "print(y_test.shape) \n",
        "\n",
        "# (3093, 14)\n",
        "# (3093, 1)\n",
        "# (767, 14)\n",
        "# (767, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In general we decided to try out two different normalisation strategies:\n",
        "\n",
        "**norm1**\n",
        "$$\n",
        "\\text{norm1} = \\frac{\\text{x}}{\\max(\\text{x})}\n",
        "$$\n",
        "\n",
        "**norm2**\n",
        "$$\n",
        "\\text{norm2} = \\frac{\\text{x} - \\min(\\text{x})}{\\max(\\text{x}) - \\min(\\text{x})}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### normalization strategy 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train set \n",
        "X_train['peak_area_norm1'] = X_train.groupby(['lab', 'compound'])['peak_area'].transform(lambda x: x / x.max())\n",
        "X_train['c_real_M_norm1'] = X_train.groupby(['lab', 'compound'])['c_real_M'].transform(lambda x: x / x.max())\n",
        "X_train['rf_norm1'] = X_train.groupby(['lab', 'compound'])['rf'].transform(lambda x: x / x.max())\n",
        "X_train['rf_error_norm1'] = X_train.groupby(['lab', 'compound'])['rf_error'].transform(lambda x: x / x.max())\n",
        "X_train['residuals_norm1'] = X_train.groupby(['lab', 'compound'])['residuals'].transform(lambda x: x / x.max())\n",
        "X_train['abs_residuals_norm1'] = X_train.groupby(['lab', 'compound'])['abs_residuals'].transform(lambda x: x / x.max())\n",
        "\n",
        "# test set \n",
        "X_test['peak_area_norm1'] = X_test.groupby(['lab', 'compound'])['peak_area'].transform(lambda x: x / x.max())\n",
        "X_test['c_real_M_norm1'] = X_test.groupby(['lab', 'compound'])['c_real_M'].transform(lambda x: x / x.max())\n",
        "X_test['rf_norm1'] = X_test.groupby(['lab', 'compound'])['rf'].transform(lambda x: x / x.max())\n",
        "X_test['rf_error_norm1'] = X_test.groupby(['lab', 'compound'])['rf_error'].transform(lambda x: x / x.max())\n",
        "X_test['residuals_norm1'] = X_test.groupby(['lab', 'compound'])['residuals'].transform(lambda x: x / x.max())\n",
        "X_test['abs_residuals_norm1'] = X_test.groupby(['lab', 'compound'])['abs_residuals'].transform(lambda x: x / x.max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### normalization strategy 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "columns_to_scale = ['peak_area', 'c_real_M', 'rf', 'rf_error', 'residuals', 'abs_residuals']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "def scale_columns(group):\n",
        "    for col in columns_to_scale:\n",
        "        group[f'{col}_norm2'] = scaler.fit_transform(group[[col]])\n",
        "    return group\n",
        "\n",
        "\n",
        "X_train = X_train.groupby(['lab', 'compound'], group_keys = False).apply(scale_columns) # group_keys = False to not include group keys in the resulting df\n",
        "X_test = X_test.groupby(['lab', 'compound'], group_keys = False).apply(scale_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WliS5ii_PVS3"
      },
      "outputs": [],
      "source": [
        "## Decide on features for modelling\n",
        "#features = ['peak_area','c_real_M']\n",
        "#features = ['RT','peak_area','c_real_M']\n",
        "#features = ['RT','peak_area','c_real_M', 'rf', 'rf_error']\n",
        "#features = ['RT','peak_area','c_real_M', 'rf', 'rf_error', 'slope', 'intercept', 'residuals', 'abs_residuals']\n",
        "features = ['RT','peak_area_norm1','c_real_M_norm1', 'rf_norm1', 'rf_error_norm1', 'slope', 'intercept', 'residuals_norm1', 'abs_residuals_norm1'] # best features\n",
        "#eatures = ['RT','peak_area_norm2','c_real_M_norm2', 'rf_norm2', 'rf_error_norm2', 'slope', 'intercept', 'residuals_norm2', 'abs_residuals_norm2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_sel = X_train[features]\n",
        "X_test_sel = X_test[features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converting labels to 0 (linear) and 1 (non-linear) \n",
        "y_train = y_train.replace({'linear': 0, 'non-linear': 1})\n",
        "y_test = y_test.replace({'linear': 0, 'non-linear': 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Libraries\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the labels (y_train and y_test) into 1D arrays\n",
        "y_train_1D = y_train.values.ravel()\n",
        "y_test_1D = y_test.values.ravel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### NB! No need to rerun the cell below unless you want to check the parameter search or make changes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Best Hyperparameters:\n",
            " {'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'bootstrap': True}\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "# Hyperparameter search\n",
        "param_distributions = {\n",
        "    'n_estimators': [50, 100, 300, 500],\n",
        "    'max_depth': [None, 10, 30, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Initialize the base model\n",
        "rf = RandomForestClassifier(random_state = 1)\n",
        "\n",
        "# Set up the RandomizedSearchCV object\n",
        "rf_random_search = RandomizedSearchCV(\n",
        "    estimator = rf,\n",
        "    param_distributions = param_distributions,\n",
        "    n_iter = 100,\n",
        "    cv = 5, \n",
        "    verbose = 2,\n",
        "    random_state = 1,\n",
        "    n_jobs = -1 # uses all cores!!\n",
        ")\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the training data\n",
        "rf_random_search.fit(X_train_sel, y_train_1D)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\\n\", rf_random_search.best_params_)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best Hyperparameters RF: </br>\n",
        "{'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'bootstrap': True}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC Score: 90.99%\n",
            "Accuracy Testset: 82.64%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84       424\n",
            "           1       0.80      0.81      0.81       342\n",
            "\n",
            "    accuracy                           0.83       766\n",
            "   macro avg       0.82      0.82      0.82       766\n",
            "weighted avg       0.83      0.83      0.83       766\n",
            "\n",
            "Confusion Matrix:\n",
            " [[356  68]\n",
            " [ 65 277]]\n"
          ]
        }
      ],
      "source": [
        "# Set up RF model using the optimal hyperparameters\n",
        "best_rf = RandomForestClassifier(random_state = 1,\n",
        "                                 n_estimators = 50,\n",
        "                                 min_samples_split = 10,\n",
        "                                 min_samples_leaf = 4,\n",
        "                                 max_features = 'log2',\n",
        "                                 max_depth = 10,\n",
        "                                 criterion = 'entropy',\n",
        "                                 bootstrap = True)\n",
        "\n",
        "# Fit the model with the best hyperparameters on the full oversampled training data\n",
        "best_rf.fit(X_train_sel, y_train_1D)\n",
        "\n",
        "# Predicting probabilities on the validation set for AUC calculation\n",
        "prob_predictions_rf = best_rf.predict_proba(X_test_sel)[:, 1]\n",
        "\n",
        "# Calculate AUC\n",
        "auc_score = roc_auc_score(y_test_1D, prob_predictions_rf)\n",
        "print(f\"AUC Score: {auc_score:.2%}\")\n",
        "\n",
        "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
        "class_predictions_rf = best_rf.predict(X_test_sel)\n",
        "\n",
        "# Evaluating the model on the validation set\n",
        "test_accuracy_rf = accuracy_score(y_test_1D, class_predictions_rf)\n",
        "print(f\"Accuracy Testset: {test_accuracy_rf:.2%}\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_1D, class_predictions_rf))\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix_rf = confusion_matrix(y_test_1D, class_predictions_rf)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results from RF model\n",
        "\n",
        "    AUC: 90.99% \n",
        "    Accuracy: 82.64%\n",
        "    Classification Report: \n",
        "                   precision    recall  f1-score   support\n",
        "\n",
        "               0       0.85      0.84      0.84       424\n",
        "               1       0.80      0.81      0.81       342\n",
        "\n",
        "        accuracy                           0.83       766\n",
        "       macro avg       0.82      0.82      0.82       766\n",
        "    weighted avg       0.83      0.83      0.83       766\n",
        "\n",
        "    Confusion Matrix: \n",
        "     [[356  68]        ([[TN FP] \n",
        "     [ 65 277]]         [ FN TP]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 766 entries, 0 to 765\n",
            "Data columns (total 28 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   lab                  766 non-null    object \n",
            " 1   compound             766 non-null    object \n",
            " 2   sample_type          766 non-null    object \n",
            " 3   RT                   766 non-null    float64\n",
            " 4   sample               766 non-null    object \n",
            " 5   peak_area            766 non-null    float64\n",
            " 6   c_real_M             766 non-null    float64\n",
            " 7   rf                   766 non-null    float64\n",
            " 8   rf_error             766 non-null    float64\n",
            " 9   slope                766 non-null    float64\n",
            " 10  intercept            766 non-null    float64\n",
            " 11  residuals            766 non-null    float64\n",
            " 12  abs_residuals        766 non-null    float64\n",
            " 13  id                   766 non-null    object \n",
            " 14  peak_area_norm1      766 non-null    float64\n",
            " 15  c_real_M_norm1       766 non-null    float64\n",
            " 16  rf_norm1             766 non-null    float64\n",
            " 17  rf_error_norm1       766 non-null    float64\n",
            " 18  residuals_norm1      766 non-null    float64\n",
            " 19  abs_residuals_norm1  766 non-null    float64\n",
            " 20  peak_area_norm2      766 non-null    float64\n",
            " 21  c_real_M_norm2       766 non-null    float64\n",
            " 22  rf_norm2             766 non-null    float64\n",
            " 23  rf_error_norm2       766 non-null    float64\n",
            " 24  residuals_norm2      766 non-null    float64\n",
            " 25  abs_residuals_norm2  766 non-null    float64\n",
            " 26  actual_labels        766 non-null    int64  \n",
            " 27  predicted_labels     766 non-null    int64  \n",
            "dtypes: float64(21), int64(2), object(5)\n",
            "memory usage: 167.7+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "## Adding the real and predicted labels to testset\n",
        "\n",
        "# Convert the actual and predicted labels to pandas Series (for compatibility)\n",
        "actual_labels = pd.Series(y_test_1D, name='actual_labels')\n",
        "predicted_labels = pd.Series(class_predictions_rf, name='predicted_labels')\n",
        "\n",
        "# Reset the index of X_test to allow for a clean concatenation\n",
        "X_test_reset = X_test.reset_index(drop=True)\n",
        "\n",
        "# Concatenate the features with the actual and predicted labels\n",
        "RF_test_set = pd.concat([X_test_reset, actual_labels, predicted_labels], axis=1)\n",
        "\n",
        "# Display the first few rows of the new DataFrame\n",
        "print(RF_test_set.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Calculate the slope for linear points based on expert labels (slope_expert) and predicted labels (pred_slope) for each compound and lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def calculate_slope(group, label_column):\n",
        "    # Filter out only the linear points\n",
        "    linear_points = group[group[label_column] == 0]\n",
        "\n",
        "    # Check if there are enough points to fit a line\n",
        "    if len(linear_points) >= 3:\n",
        "        # Fit linear regression\n",
        "        model = LinearRegression()\n",
        "        # Assuming 'feature1' and 'feature2' are the features to be used for regression\n",
        "        model.fit(linear_points[['c_real_M']], linear_points['peak_area'])\n",
        "        # Return the slope\n",
        "        return model.coef_[0]\n",
        "    else:\n",
        "        # Return NaN or some default value if not enough points\n",
        "        return float('nan')\n",
        "\n",
        "# Group by 'lab' and 'compound', then apply the calculate_slope function\n",
        "slope_expert = RF_test_set.groupby(['lab', 'compound']).apply(calculate_slope, label_column='actual_labels')\n",
        "pred_slope = RF_test_set.groupby(['lab', 'compound']).apply(calculate_slope, label_column='predicted_labels')\n",
        "\n",
        "# Convert to dataframes\n",
        "slope_expert_df = slope_expert.reset_index().rename(columns={0: 'slope_expert'})\n",
        "pred_slope_df = pred_slope.reset_index().rename(columns={0: 'pred_slope'})\n",
        "\n",
        "## Add slopes back to RF_test_set df\n",
        "# Merge slope_expert\n",
        "RF_test_set = RF_test_set.merge(slope_expert_df, on=['lab', 'compound'], how='left')\n",
        "\n",
        "# Merge pred_slope\n",
        "RF_test_set = RF_test_set.merge(pred_slope_df, on=['lab', 'compound'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lab</th>\n",
              "      <th>compound</th>\n",
              "      <th>sample_type</th>\n",
              "      <th>RT</th>\n",
              "      <th>sample</th>\n",
              "      <th>peak_area</th>\n",
              "      <th>c_real_M</th>\n",
              "      <th>rf</th>\n",
              "      <th>rf_error</th>\n",
              "      <th>slope</th>\n",
              "      <th>...</th>\n",
              "      <th>peak_area_norm2</th>\n",
              "      <th>c_real_M_norm2</th>\n",
              "      <th>rf_norm2</th>\n",
              "      <th>rf_error_norm2</th>\n",
              "      <th>residuals_norm2</th>\n",
              "      <th>abs_residuals_norm2</th>\n",
              "      <th>actual_labels</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>slope_expert</th>\n",
              "      <th>pred_slope</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal1</td>\n",
              "      <td>1.488900e+09</td>\n",
              "      <td>1.930000e-06</td>\n",
              "      <td>7.714507e+14</td>\n",
              "      <td>7.202735e+13</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.818695</td>\n",
              "      <td>0.415775</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.369017</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.747159e+14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal2</td>\n",
              "      <td>4.773961e+08</td>\n",
              "      <td>8.290000e-07</td>\n",
              "      <td>5.758698e+14</td>\n",
              "      <td>1.235535e+14</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318120</td>\n",
              "      <td>0.426942</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.747159e+14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal3</td>\n",
              "      <td>3.141558e+08</td>\n",
              "      <td>4.240000e-07</td>\n",
              "      <td>7.409334e+14</td>\n",
              "      <td>4.151011e+13</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.208076</td>\n",
              "      <td>0.216143</td>\n",
              "      <td>0.690951</td>\n",
              "      <td>0.069758</td>\n",
              "      <td>0.828776</td>\n",
              "      <td>0.126953</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.747159e+14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal4</td>\n",
              "      <td>1.646883e+08</td>\n",
              "      <td>2.480000e-07</td>\n",
              "      <td>6.640656e+14</td>\n",
              "      <td>3.535771e+13</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.107316</td>\n",
              "      <td>0.124537</td>\n",
              "      <td>0.369185</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.738975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.747159e+14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal5</td>\n",
              "      <td>6.933636e+07</td>\n",
              "      <td>8.510000e-08</td>\n",
              "      <td>8.147633e+14</td>\n",
              "      <td>1.153400e+14</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043037</td>\n",
              "      <td>0.039750</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.906872</td>\n",
              "      <td>0.902189</td>\n",
              "      <td>0.230739</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.747159e+14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  lab  compound sample_type    RT sample     peak_area      c_real_M  \\\n",
              "0  L1  Atrazine         cal  4.92   cal1  1.488900e+09  1.930000e-06   \n",
              "1  L1  Atrazine         cal  4.92   cal2  4.773961e+08  8.290000e-07   \n",
              "2  L1  Atrazine         cal  4.92   cal3  3.141558e+08  4.240000e-07   \n",
              "3  L1  Atrazine         cal  4.92   cal4  1.646883e+08  2.480000e-07   \n",
              "4  L1  Atrazine         cal  4.92   cal5  6.933636e+07  8.510000e-08   \n",
              "\n",
              "             rf      rf_error         slope  ...  peak_area_norm2  \\\n",
              "0  7.714507e+14  7.202735e+13  7.602001e+14  ...         1.000000   \n",
              "1  5.758698e+14  1.235535e+14  7.602001e+14  ...         0.318120   \n",
              "2  7.409334e+14  4.151011e+13  7.602001e+14  ...         0.208076   \n",
              "3  6.640656e+14  3.535771e+13  7.602001e+14  ...         0.107316   \n",
              "4  8.147633e+14  1.153400e+14  7.602001e+14  ...         0.043037   \n",
              "\n",
              "   c_real_M_norm2  rf_norm2 rf_error_norm2  residuals_norm2  \\\n",
              "0        1.000000  0.818695       0.415775         1.000000   \n",
              "1        0.426942  0.000000       1.000000         0.000000   \n",
              "2        0.216143  0.690951       0.069758         0.828776   \n",
              "3        0.124537  0.369185       0.000000         0.738975   \n",
              "4        0.039750  1.000000       0.906872         0.902189   \n",
              "\n",
              "   abs_residuals_norm2  actual_labels  predicted_labels  slope_expert  \\\n",
              "0             0.369017              0                 0  7.747159e+14   \n",
              "1             1.000000              1                 1  7.747159e+14   \n",
              "2             0.126953              0                 0  7.747159e+14   \n",
              "3             0.000000              0                 0  7.747159e+14   \n",
              "4             0.230739              0                 0  7.747159e+14   \n",
              "\n",
              "     pred_slope  \n",
              "0  7.747159e+14  \n",
              "1  7.747159e+14  \n",
              "2  7.747159e+14  \n",
              "3  7.747159e+14  \n",
              "4  7.747159e+14  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RF_test_set.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### How do we now use these slopes to evaluate the model??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               feature  importance\n",
            "3             rf_norm1    0.354963\n",
            "2       c_real_M_norm1    0.118938\n",
            "1      peak_area_norm1    0.118811\n",
            "4       rf_error_norm1    0.086824\n",
            "6            intercept    0.084462\n",
            "0                   RT    0.073340\n",
            "7      residuals_norm1    0.066759\n",
            "5                slope    0.049460\n",
            "8  abs_residuals_norm1    0.046443\n"
          ]
        }
      ],
      "source": [
        "# Get feature importances\n",
        "importances = best_rf.feature_importances_\n",
        "\n",
        "# Assuming X_train is a DataFrame with column names\n",
        "feature_names = X_train_sel.columns\n",
        "\n",
        "# Create a DataFrame for feature importances\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance\n",
        "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "# Display the feature importances\n",
        "print(feature_importances_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGBoost\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### No need to rerun code block below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Best parameters:\n",
            " {'subsample': 0.7, 'n_estimators': 500, 'min_child_weight': 10, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "# Define the hyperparameter grid to search for best settings\n",
        "param_grid = {\n",
        "    'max_depth': [3, 6, 10],\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'subsample': [0.5, 0.7, 1.0],\n",
        "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier\n",
        "xgb = XGBClassifier(random_state = 1, use_label_encoder = False, eval_metric = 'logloss')\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator = xgb,\n",
        "    param_distributions = param_grid,\n",
        "    n_iter = 100, \n",
        "    scoring = 'roc_auc', \n",
        "    cv = 5,\n",
        "    verbose = 2,\n",
        "    random_state = 1,\n",
        "    n_jobs = -1  # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the training data\n",
        "random_search.fit(X_train_sel, y_train_1D)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters:\\n\", random_search.best_params_)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best parameters XGBoost: </br>\n",
        " {'subsample': 0.7, 'n_estimators': 500, 'min_child_weight': 10, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 1.0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC Score: 90.75%\n",
            "Accuracy Testset: 81.46%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       424\n",
            "           1       0.79      0.80      0.79       342\n",
            "\n",
            "    accuracy                           0.81       766\n",
            "   macro avg       0.81      0.81      0.81       766\n",
            "weighted avg       0.81      0.81      0.81       766\n",
            "\n",
            "[[352  72]\n",
            " [ 70 272]]\n"
          ]
        }
      ],
      "source": [
        "# Set up XGBoost model using the optimal hyperparameters\n",
        "best_xgb = XGBClassifier(random_state = 1,\n",
        "                         use_label_encoder = False,\n",
        "                         eval_metric = 'logloss',\n",
        "                         subsample = 0.7,\n",
        "                         n_estimators = 500,\n",
        "                         min_child_weight = 10,\n",
        "                         max_depth = 6,\n",
        "                         learning_rate = 0.01,\n",
        "                         colsample_bytree = 1.0)\n",
        "\n",
        "# Train the best estimator on the full training data\n",
        "best_xgb.fit(X_train_sel, y_train_1D)\n",
        "\n",
        "# Predict probabilities on the validation set\n",
        "prob_predictions_xgb = best_xgb.predict_proba(X_test_sel)[:, 1]\n",
        "\n",
        "# Compute the ROC AUC score\n",
        "val_roc_auc = roc_auc_score(y_test_1D, prob_predictions_xgb)\n",
        "print(f\"AUC Score: {val_roc_auc:.2%}\")\n",
        "\n",
        "# Predict on the validation set\n",
        "class_predictions_xgb = best_xgb.predict(X_test_sel)\n",
        "\n",
        "# Compute accuracy\n",
        "test_accuracy = accuracy_score(y_test_1D, class_predictions_xgb)\n",
        "print(f\"Accuracy Testset: {test_accuracy:.2%}\")\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test_1D, class_predictions_xgb))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(confusion_matrix(y_test_1D, class_predictions_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results from XGBoost model\n",
        "\n",
        "    AUC: 90.75% \n",
        "    Accuracy: 81.46%\n",
        "    Classification Report: \n",
        "                   precision    recall  f1-score   support\n",
        "\n",
        "               0       0.83      0.83      0.83       424\n",
        "               1       0.79      0.80      0.79       342\n",
        "\n",
        "        accuracy                           0.81       766\n",
        "       macro avg       0.81      0.81      0.81       766\n",
        "    weighted avg       0.81      0.81      0.81       766\n",
        "\n",
        "    Confusion Matrix: \n",
        "     [[352  72]        ([[TN FP] \n",
        "     [ 70 272]]         [ FN TP]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 766 entries, 0 to 765\n",
            "Data columns (total 28 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   lab                  766 non-null    object \n",
            " 1   compound             766 non-null    object \n",
            " 2   sample_type          766 non-null    object \n",
            " 3   RT                   766 non-null    float64\n",
            " 4   sample               766 non-null    object \n",
            " 5   peak_area            766 non-null    float64\n",
            " 6   c_real_M             766 non-null    float64\n",
            " 7   rf                   766 non-null    float64\n",
            " 8   rf_error             766 non-null    float64\n",
            " 9   slope                766 non-null    float64\n",
            " 10  intercept            766 non-null    float64\n",
            " 11  residuals            766 non-null    float64\n",
            " 12  abs_residuals        766 non-null    float64\n",
            " 13  id                   766 non-null    object \n",
            " 14  peak_area_norm1      766 non-null    float64\n",
            " 15  c_real_M_norm1       766 non-null    float64\n",
            " 16  rf_norm1             766 non-null    float64\n",
            " 17  rf_error_norm1       766 non-null    float64\n",
            " 18  residuals_norm1      766 non-null    float64\n",
            " 19  abs_residuals_norm1  766 non-null    float64\n",
            " 20  peak_area_norm2      766 non-null    float64\n",
            " 21  c_real_M_norm2       766 non-null    float64\n",
            " 22  rf_norm2             766 non-null    float64\n",
            " 23  rf_error_norm2       766 non-null    float64\n",
            " 24  residuals_norm2      766 non-null    float64\n",
            " 25  abs_residuals_norm2  766 non-null    float64\n",
            " 26  actual_labels        766 non-null    int64  \n",
            " 27  predicted_labels     766 non-null    int32  \n",
            "dtypes: float64(21), int32(1), int64(1), object(5)\n",
            "memory usage: 164.7+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "## Adding the real and predicted labels to testset\n",
        "\n",
        "# Convert the actual and predicted labels to pandas Series (for compatibility)\n",
        "actual_labels = pd.Series(y_test_1D, name='actual_labels')\n",
        "predicted_labels = pd.Series(class_predictions_xgb, name='predicted_labels')\n",
        "\n",
        "# Reset the index of X_test to allow for a clean concatenation\n",
        "X_test_reset = X_test.reset_index(drop=True)\n",
        "\n",
        "# Concatenate the features with the actual and predicted labels\n",
        "xgb_test_set = pd.concat([X_test_reset, actual_labels, predicted_labels], axis=1)\n",
        "\n",
        "# Display the first few rows of the new DataFrame\n",
        "print(xgb_test_set.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_slope(group, label_column):\n",
        "    # Filter out only the linear points\n",
        "    linear_points = group[group[label_column] == 0]\n",
        "\n",
        "    # Check if there are enough points to fit a line\n",
        "    if len(linear_points) >= 3:\n",
        "        # Fit linear regression\n",
        "        model = LinearRegression()\n",
        "        # Assuming 'feature1' and 'feature2' are the features to be used for regression\n",
        "        model.fit(linear_points[['c_real_M']], linear_points['peak_area'])\n",
        "        # Return the slope\n",
        "        return model.coef_[0]\n",
        "    else:\n",
        "        # Return NaN or some default value if not enough points\n",
        "        return float('nan')\n",
        "\n",
        "# Group by 'lab' and 'compound', then apply the calculate_slope function\n",
        "slope_expert = xgb_test_set.groupby(['lab', 'compound']).apply(calculate_slope, label_column='actual_labels')\n",
        "pred_slope = xgb_test_set.groupby(['lab', 'compound']).apply(calculate_slope, label_column='predicted_labels')\n",
        "\n",
        "# Convert to dataframes\n",
        "slope_expert_df = slope_expert.reset_index().rename(columns={0: 'slope_expert'})\n",
        "pred_slope_df = pred_slope.reset_index().rename(columns={0: 'pred_slope'})\n",
        "\n",
        "## Add slopes back to RF_test_set df\n",
        "# Merge slope_expert\n",
        "xgb_test_set = xgb_test_set.merge(slope_expert_df, on=['lab', 'compound'], how='left')\n",
        "\n",
        "# Merge pred_slope\n",
        "xgb_test_set = xgb_test_set.merge(pred_slope_df, on=['lab', 'compound'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lab</th>\n",
              "      <th>compound</th>\n",
              "      <th>sample_type</th>\n",
              "      <th>RT</th>\n",
              "      <th>sample</th>\n",
              "      <th>peak_area</th>\n",
              "      <th>c_real_M</th>\n",
              "      <th>rf</th>\n",
              "      <th>rf_error</th>\n",
              "      <th>slope</th>\n",
              "      <th>...</th>\n",
              "      <th>peak_area_norm2</th>\n",
              "      <th>c_real_M_norm2</th>\n",
              "      <th>rf_norm2</th>\n",
              "      <th>rf_error_norm2</th>\n",
              "      <th>residuals_norm2</th>\n",
              "      <th>abs_residuals_norm2</th>\n",
              "      <th>actual_labels</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>slope_expert</th>\n",
              "      <th>pred_slope</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal1</td>\n",
              "      <td>1.488900e+09</td>\n",
              "      <td>1.930000e-06</td>\n",
              "      <td>7.714507e+14</td>\n",
              "      <td>7.202735e+13</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.818695</td>\n",
              "      <td>0.415775</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.369017</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.602001e+14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal2</td>\n",
              "      <td>4.773961e+08</td>\n",
              "      <td>8.290000e-07</td>\n",
              "      <td>5.758698e+14</td>\n",
              "      <td>1.235535e+14</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318120</td>\n",
              "      <td>0.426942</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.602001e+14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal3</td>\n",
              "      <td>3.141558e+08</td>\n",
              "      <td>4.240000e-07</td>\n",
              "      <td>7.409334e+14</td>\n",
              "      <td>4.151011e+13</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.208076</td>\n",
              "      <td>0.216143</td>\n",
              "      <td>0.690951</td>\n",
              "      <td>0.069758</td>\n",
              "      <td>0.828776</td>\n",
              "      <td>0.126953</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.602001e+14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal4</td>\n",
              "      <td>1.646883e+08</td>\n",
              "      <td>2.480000e-07</td>\n",
              "      <td>6.640656e+14</td>\n",
              "      <td>3.535771e+13</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.107316</td>\n",
              "      <td>0.124537</td>\n",
              "      <td>0.369185</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.738975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.602001e+14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L1</td>\n",
              "      <td>Atrazine</td>\n",
              "      <td>cal</td>\n",
              "      <td>4.92</td>\n",
              "      <td>cal5</td>\n",
              "      <td>6.933636e+07</td>\n",
              "      <td>8.510000e-08</td>\n",
              "      <td>8.147633e+14</td>\n",
              "      <td>1.153400e+14</td>\n",
              "      <td>7.602001e+14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043037</td>\n",
              "      <td>0.039750</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.906872</td>\n",
              "      <td>0.902189</td>\n",
              "      <td>0.230739</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.747159e+14</td>\n",
              "      <td>7.602001e+14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  lab  compound sample_type    RT sample     peak_area      c_real_M  \\\n",
              "0  L1  Atrazine         cal  4.92   cal1  1.488900e+09  1.930000e-06   \n",
              "1  L1  Atrazine         cal  4.92   cal2  4.773961e+08  8.290000e-07   \n",
              "2  L1  Atrazine         cal  4.92   cal3  3.141558e+08  4.240000e-07   \n",
              "3  L1  Atrazine         cal  4.92   cal4  1.646883e+08  2.480000e-07   \n",
              "4  L1  Atrazine         cal  4.92   cal5  6.933636e+07  8.510000e-08   \n",
              "\n",
              "             rf      rf_error         slope  ...  peak_area_norm2  \\\n",
              "0  7.714507e+14  7.202735e+13  7.602001e+14  ...         1.000000   \n",
              "1  5.758698e+14  1.235535e+14  7.602001e+14  ...         0.318120   \n",
              "2  7.409334e+14  4.151011e+13  7.602001e+14  ...         0.208076   \n",
              "3  6.640656e+14  3.535771e+13  7.602001e+14  ...         0.107316   \n",
              "4  8.147633e+14  1.153400e+14  7.602001e+14  ...         0.043037   \n",
              "\n",
              "   c_real_M_norm2  rf_norm2 rf_error_norm2  residuals_norm2  \\\n",
              "0        1.000000  0.818695       0.415775         1.000000   \n",
              "1        0.426942  0.000000       1.000000         0.000000   \n",
              "2        0.216143  0.690951       0.069758         0.828776   \n",
              "3        0.124537  0.369185       0.000000         0.738975   \n",
              "4        0.039750  1.000000       0.906872         0.902189   \n",
              "\n",
              "   abs_residuals_norm2  actual_labels  predicted_labels  slope_expert  \\\n",
              "0             0.369017              0                 0  7.747159e+14   \n",
              "1             1.000000              1                 0  7.747159e+14   \n",
              "2             0.126953              0                 0  7.747159e+14   \n",
              "3             0.000000              0                 0  7.747159e+14   \n",
              "4             0.230739              0                 0  7.747159e+14   \n",
              "\n",
              "     pred_slope  \n",
              "0  7.602001e+14  \n",
              "1  7.602001e+14  \n",
              "2  7.602001e+14  \n",
              "3  7.602001e+14  \n",
              "4  7.602001e+14  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb_test_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               feature  importance\n",
            "3             rf_norm1    0.327996\n",
            "1      peak_area_norm1    0.231957\n",
            "4       rf_error_norm1    0.085690\n",
            "2       c_real_M_norm1    0.080915\n",
            "0                   RT    0.062289\n",
            "6            intercept    0.061032\n",
            "7      residuals_norm1    0.053742\n",
            "5                slope    0.048285\n",
            "8  abs_residuals_norm1    0.048092\n"
          ]
        }
      ],
      "source": [
        "# Get feature importances\n",
        "importances = best_xgb.feature_importances_\n",
        "\n",
        "# Assuming X_train is a DataFrame with column names\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Create a DataFrame for feature importances\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance\n",
        "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "# Display the feature importances\n",
        "print(feature_importances_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
